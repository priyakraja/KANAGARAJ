# -*- coding: utf-8 -*-
"""15,16  SEP CONTINUATION  STRM  AKBAR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aVq81BLtziCkstgFZJySiJb57vlWaav-
"""

# Only for the importation
# %pip install streamlit
# %pip install PyMuPDF
# %pip install docx2txt

# Only for the importation
#!pip install streamlit
#!pip install PyMuPDF
#!pip install docx2txt

import streamlit as st
import re
import nltk
import fitz
import docx2txt
import joblib
import json

nltk.download('stopwords')
nltk.download('punkt')
from nltk.corpus import stopwords
sw = set(stopwords.words('english'))

def preprocess(resume):
    resume = re.sub('[^a-zA-Z]', ' ', resume)
    text = resume.lower()
    text = text.split()
    text = [words for words in text if words not in sw]
    text = ' '.join(text)
    return text

def extract_file(resume):
    fn = resume.name.lower()
    with open(fn,"wb")as f:
        f.write(resume.read())

def extract_file(resume):
    fn = resume.name.lower()
    with open(fn, "wb") as f:
        f.write(resume.read())

    if fn.endswith(".pdf"):
        try:
            pdf_file = fitz.open(fn)
            text = ""
            for page in pdf_file:
                text += page.get_text()
            return text
        except Exception as e:
            return f"error reading the file {e}"

    elif fn.endwith(",docx"):
        try:
            docxfile = doc2txt.process(fn)
            return docxfile
        except Exception as e:
            return f"error reading the file {e}"

    else:
        return "Unsupported file format. Please upload a PDF or DOCX file."

import joblib

model = joblib.load("model.pkl")
vect = joblib.load("vectorizer.pkl")
encoder = joblib.load("LEencoder.pkl")

def predict_roles(model, vectorizer, encoder, text, top_n=5):
    vec = vectorizer.transform([text])
    probs = model.predict_proba(vec)
    classes = model.classes_
    top_indices = probs.argsort()[-top_n:][::-1]
    top_classes = classes[top_indices]
    top_probs = probs[top_indices]

    decoded_roles = {
        encoder.inverse_transform([int(role)]): prob
        for role, prob in zip(top_classes, top_probs)
    }
    return decoded_roles

import os
print(os.getcwd())

import json

file_path = r"C:\Users\Ummuhaani\Downloads\skills.json"

# Open and read the JSON file
with open ("skills.json", "r") as f:
    job_skills = json.load(f)

st.title("Resume Role Predictor")
uploaded_file=st.file_uploader("Upload your resume(PDF OR DOCX)",type=["pdf","docx"])

if uploaded_file is not None:
    text=extract_file(uploaded_file)

    if "error" not in text.lower() and "unsupported" not in text.lower():
       st.subheader("Extracted Resume Text")
       #st.write(text)[:500]+"..."if len(text)>500 else st.write(text)
       processed=preprocess(text)
       predictions=predict_roles(model,vect,encoder,processed)

       st.subheader("Top Predicted Roles")
       for role,prob in predictions.items():
           st.write(f"**{role}**: {prob*100:.2f}")

       best_role=max(predictions,key=predictions.get)
       if best_role in job_skills:
           st.subheader(f"required skills for{best_role}")
           st.write(",".join(job_skills[best_role]))
    else:
       st.error(text)
